{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (0.3.19)\n",
      "Requirement already satisfied: langchain_community in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (0.3.17)\n",
      "Requirement already satisfied: langchain_chroma in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (0.2.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langchain) (0.3.36)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langchain) (0.2.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langchain) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langchain_community) (2.7.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langchain_chroma) (0.6.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.115.8)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.6.5)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.15.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.30.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.15.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.62.2)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (32.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (13.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: pyproject_hooks in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from build>=1.0.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.45.3)\n",
      "Requirement already satisfied: anyio in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.9)\n",
      "Requirement already satisfied: coloredlogs in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (4.25.3)\n",
      "Requirement already satisfied: sympy in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (8.5.0)\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.11.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.67.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.15.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.15.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.51b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.6)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2.19.1)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.29.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from typer>=0.9.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.5.4)\n",
      "Requirement already satisfied: mypy_extensions>=0.3.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (14.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (4.9)\n",
      "Requirement already satisfied: filelock in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (2025.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.1.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.7.0,>=0.4.0->langchain_chroma) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain_community langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model_name=\"deepseek-r1:8b\"\n",
    "llm = ChatOllama(model=model_name,\n",
    "                            base_url=\"http://10.168.6.34:11434\",temperature = 0,mirostat_tau=2.0,top_k=10,top_p=0.5\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load, chunk and index the contents of the blog.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43130"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1719151/3237731207.py:5: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  local_embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 使用关键字参数初始化 OllamaEmbeddings\n",
    "local_embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "#vectorstore = Chroma.from_documents(documents=splits, embedding=local_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "db = FAISS.from_documents(documents=splits, embedding=local_embedding)\n",
    "# db = FAISS.from_documents(texts, local_embeddings,normalize_L2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "/home/uniteomics/miniforge-pypy3/envs/deepseek/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:1076: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='7e1c0a70-1f6a-4378-899e-db6985fb6698', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), -276.95418515823656), (Document(id='5bfe4873-c271-4f91-8af4-7609d3dc9619', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'), -301.58477645402), (Document(id='44b7be3c-e0e6-46a8-953e-0c6c932f1bdf', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.'), -303.3120176948566), (Document(id='27148fce-f280-446a-809c-54e43b66ca56', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.'), -310.0720862717837)]\n",
      "  self.vectorstore.similarity_search_with_relevance_scores(\n",
      "No relevant docs were retrieved using the relevance score threshold 0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, so I need to figure out what Task Decomposition is. From the context given, it's mentioned as a method used in project management. It breaks down larger tasks into smaller, more manageable parts. This makes each task easier to handle and track. By doing this, teams can work on individual pieces without getting overwhelmed by the whole project at once.\\n\\nI think Task Decomposition is about breaking projects into smaller tasks. That way, each part can be assigned to team members, tracked individually, and then combined later. It probably helps in managing time better and ensuring that everyone knows their role in the project. This process likely improves productivity because it avoids feeling overwhelmed with too much work at once.\\n\\nI'm not entirely sure if there are different types of decomposition or specific steps involved beyond just breaking tasks down. Maybe it's about identifying dependencies between these smaller tasks as well? Or perhaps using some kind of hierarchy to organize them. But the main idea seems clear: making larger tasks more manageable by splitting them into smaller, actionable parts.\\n</think>\\n\\nTask Decomposition is a method used in project management that breaks down large tasks into smaller, more manageable components. This process allows teams to tackle each part individually, improving productivity and organization. By dividing tasks, it simplifies tracking progress and assigning responsibilities, making complex projects easier to handle.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "# retriever = vectorstore.as_retriever()\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(), llm=llm\n",
    ")\n",
    "\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": .1})\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1719151/3122358776.py:2: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='18e1bd7a-6830-4af4-be26-94304c56c2c3', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), -276.9541419998637), (Document(id='c79a423d-9704-42c2-ba69-6b8c0825734b', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'), -301.58473329564714), (Document(id='35abc041-f75e-4b2a-8412-b69f93f33261', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.'), -303.3119745364837), (Document(id='630209d5-c2ee-4a67-9359-8cca86c046ef', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.'), -310.0720862717837)]\n",
      "  db.similarity_search_with_relevance_scores(query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(Document(id='18e1bd7a-6830-4af4-be26-94304c56c2c3', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'),\n",
       "  -276.9541419998637),\n",
       " (Document(id='c79a423d-9704-42c2-ba69-6b8c0825734b', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'),\n",
       "  -301.58473329564714),\n",
       " (Document(id='35abc041-f75e-4b2a-8412-b69f93f33261', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.'),\n",
       "  -303.3119745364837),\n",
       " (Document(id='630209d5-c2ee-4a67-9359-8cca86c046ef', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.'),\n",
       "  -310.0720862717837)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"What is Task Decomposition?\"\n",
    "db.similarity_search_with_relevance_scores(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "# db = FAISS.from_documents(documents=splits, embedding=local_embedding)\n",
    "db = FAISS.from_documents(documents=splits, embedding=local_embedding,normalize_L2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='e5229f5d-5f92-42e2-bfb0-a440cb6451e6', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'),\n",
       "  0.4236241449371496),\n",
       " (Document(id='0fd824ee-c77c-420b-b8b5-8dadcb4458cb', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.'),\n",
       "  0.3562033486608188),\n",
       " (Document(id='14fa9ecc-65c2-4cbe-bfe8-cbb03f5d7609', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'),\n",
       "  0.3486629402874317),\n",
       " (Document(id='420e33fc-ac16-4ac0-8d2f-9d1a70c19979', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'),\n",
       "  0.34651109078985953)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"What is Task Decomposition?\"\n",
    "db.similarity_search_with_relevance_scores(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=splits, embedding=local_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1719151/3799112155.py:2: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='7e1c0a70-1f6a-4378-899e-db6985fb6698', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), -276.95418515823656), (Document(id='e68237fe-10bb-4187-835f-3dc11461d9f3', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), -276.95418515823656), (Document(id='5bfe4873-c271-4f91-8af4-7609d3dc9619', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'), -301.58477645402), (Document(id='114b2809-ecc6-4520-984a-6ce31ef19e3c', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'), -301.58477645402)]\n",
      "  vectorstore.similarity_search_with_relevance_scores(query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(Document(id='7e1c0a70-1f6a-4378-899e-db6985fb6698', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'),\n",
       "  -276.95418515823656),\n",
       " (Document(id='e68237fe-10bb-4187-835f-3dc11461d9f3', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'),\n",
       "  -276.95418515823656),\n",
       " (Document(id='5bfe4873-c271-4f91-8af4-7609d3dc9619', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'),\n",
       "  -301.58477645402),\n",
       " (Document(id='114b2809-ecc6-4520-984a-6ce31ef19e3c', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'),\n",
       "  -301.58477645402)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query=\"What is Task Decomposition?\"\n",
    "vectorstore.similarity_search_with_relevance_scores(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepseek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
